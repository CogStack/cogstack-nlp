{"general": {"device": "cpu", "relation_type_filter_pairs": [], "vocab_size": null, "lowercase": true, "cntx_left": 15, "cntx_right": 15, "window_size": 300, "limit_samples_per_class": -1, "addl_rels_max_sample_size": 200, "create_addl_rels": false, "create_addl_rels_by_type": false, "tokenizer_name": "bert", "model_name": "bert-unknown", "log_level": 20, "max_seq_length": 512, "tokenizer_special_tokens": false, "annotation_schema_tag_ids": [30522, 30523, 30524, 30525], "tokenizer_relation_annotation_special_tokens_tags": ["[s1]", "[e1]", "[s2]", "[e2]"], "tokenizer_other_special_tokens": {"pad_token": "[PAD]"}, "labels2idx": {}, "idx2labels": {}, "pin_memory": true, "seed": 13, "task": "train", "language": "en"}, "model": {"input_size": 300, "hidden_size": 768, "hidden_layers": 3, "model_size": 5120, "dropout": 0.2, "num_directions": 2, "freeze_layers": true, "padding_idx": -1, "emb_grad": true, "ignore_cpos": false, "llama_use_pooled_output": false}, "train": {"nclasses": 2, "batch_size": 25, "nepochs": 1, "lr": 0.0001, "stratified_batching": false, "batching_samples_per_class": [], "batching_minority_limit": 0, "adam_betas": [0.9, 0.999], "adam_weight_decay": 0, "adam_epsilon": 1e-08, "test_size": 0.2, "gradient_acc_steps": 1, "multistep_milestones": [2, 4, 6, 8, 12, 15, 18, 20, 22, 24, 26, 30], "multistep_lr_gamma": 0.8, "max_grad_norm": 1.0, "shuffle_data": true, "class_weights": null, "enable_class_weights": false, "score_average": "weighted", "auto_save_model": true}}